{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwrZe6ww6bTa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pprint\n",
        "import sys\n",
        "import gym\n",
        "try:\n",
        "    import Box2D\n",
        "except ModuleNotFoundError:\n",
        "    print(\"Box2D not found !!\")\n",
        "    !pip install Box2D-py\n",
        "    import Box2D\n",
        "try:\n",
        "    import gym_gridworlds\n",
        "except ModuleNotFoundError:\n",
        "    print(\"gym_gridworlds not found. so Installing rn \")\n",
        "    !pip install gym_gridworlds\n",
        "    import gym_gridworlds\n",
        "class DiscreteActions(gym.ActionWrapper):\n",
        "    def __init__(self, env, disc_to_cont):\n",
        "        super().__init__(env)\n",
        "        self.disc_to_cont = disc_to_cont\n",
        "\n",
        "        from gym.spaces import Discrete\n",
        "        self.action_space = Discrete(len(disc_to_cont))\n",
        "\n",
        "    def action(self, act):\n",
        "        return self.disc_to_cont[act]\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    import numpy as np\n",
        "    env = gym.make(\"LunarLanderContinuous-v2\")\n",
        "    wrapped_env = DiscreteActions(env, [np.array([1,0]), np.array([-1,0]),\n",
        "                                        np.array([0,1]), np.array([0,-1])])\n",
        "    print(wrapped_env.action_space)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ],
      "metadata": {
        "id": "XSAShmTe67nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn2kXS4b6bTc"
      },
      "outputs": [],
      "source": [
        "pp = pprint.PrettyPrinter(indent=2)\n",
        "env = GridworldEnv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrHpNjD66bTd"
      },
      "outputs": [],
      "source": [
        "def value_iteration(env, theta=0.0001, discount_factor=1.0):\n",
        "    def one_step_lookahead(state, V):\n",
        "        A = np.zeros(env.nA)\n",
        "        for a in range(env.nA):\n",
        "            for prob, next_state, reward, done in env.P[state][a]:\n",
        "                A[a] += prob * (reward + discount_factor * V[next_state])\n",
        "        return A\n",
        "    V = np.zeros(env.nS)\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for s in range(env.nS):\n",
        "            A = one_step_lookahead(s, V)\n",
        "            best_action_value = np.max(A)\n",
        "            delta = max(delta, np.abs(best_action_value - V[s]))\n",
        "            V[s] = best_action_value\n",
        "        if delta < theta:\n",
        "            break\n",
        "    # this is used to create a deterministic policy ie invloves less probablity using the optimal value func\n",
        "    policy = np.zeros([env.nS, env.nA])\n",
        "    for s in range(env.nS):\n",
        "        A = one_step_lookahead(s, V)\n",
        "        best_action = np.argmax(A)\n",
        "        policy[s, best_action] = 1.0\n",
        "\n",
        "    return policy, V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4zvoyji6bTd"
      },
      "outputs": [],
      "source": [
        "policy, v = value_iteration(env)\n",
        "\n",
        "print(\"Policy probability distribution:\")\n",
        "print(policy)\n",
        "print(\"\")\n",
        "\n",
        "print(\"Reshaped grid olicy (0=up, 1=right, 2=down, 3=left):\")\n",
        "print(np.reshape(np.argmax(policy, axis=1), env.shape))\n",
        "print(\"\")\n",
        "\n",
        "print(\"Value func:\")\n",
        "print(v)\n",
        "print(\"\")\n",
        "\n",
        "print(\"Reshaped grid value func:\")\n",
        "print(v.reshape(env.shape))\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v5Euf3s6bTe"
      },
      "outputs": [],
      "source": [
        "# Testing few  the value function\n",
        "expected_v = np.array([ 0, -1, -2, -3, -1, -2, -3, -2, -2, -3, -2, -1, -3, -2, -1,  0])\n",
        "np.testing.assert_array_almost_equal(v, expected_v, decimal=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mI4anIPo6bTe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}